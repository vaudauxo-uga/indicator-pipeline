# Documentation indicator-pipeline

# ğŸ§­ Vue dâ€™ensemble

- Lâ€™objectif de ce pipeline est de calculer des indicateurs Ã  partir du signal SpOâ‚‚ des fichiers de polysomnographie (*.edf* et annotations en *.csv*, *.txt* et/ou *.rtf*) disponibles sur le serveur de stockage. Les fichiers de polysomnographie sont dâ€™abord convertis au format *sleeplab* (*slf*), et stockÃ©s Ã  la fois sur le serveur de stockage et en local. Puis le calcul des indicateurs par le logiciel se fait manuellement via [ABOSA](https://zenodo.org/records/6962129), et enfin les donnÃ©es en sortie du logiciel sont intÃ©grÃ©es dans la base de donnÃ©es MARS.
- Ce pipeline a Ã©tÃ© crÃ©Ã© pour une utilisation sur une machine dÃ©diÃ©e ou une VM sous Windows.
- Les donnÃ©es dâ€™entrÃ©e sont les donnÃ©es de polysomnographie prÃ©sentes sur le serveur de stockage. En sortie, on retrouve les indicateurs calculÃ©s dans les tables MARS dÃ©diÃ©es aux mesures dâ€™oxymÃ©trie.

## ğŸ“„ Description du flux dâ€™exÃ©cution

- **Connexion au serveur SFTP** : rÃ©cupÃ©ration des fichiers .*edf* et fichiers dâ€™annotations (.*csv*, .*txt*, .*rtf*) pour les annÃ©es spÃ©cifiÃ©es.
- **Conversion sleeplab** : transformation des fichiers de polysomnographie au format sleeplab (via le module `sleeplab_converter`). Les fichiers convertis sont enregistrÃ©s:
    - sur le **serveur de stockage**, dans le dossier du patient correspondant, sous le nom `slf_PAxxxx_Vx`;
    - en **local**, dans le dossier `slf-output`, situÃ© un niveau au-dessus de la racine du projet
- **Lancement manuel dâ€™ABOSA** *(hors pipeline)* : les fichiers convertis doivent Ãªtre ouverts et analysÃ©s **manuellement** dans le logiciel ABOSA afin dâ€™y calculer les indicateurs dâ€™oxymÃ©trie. Le logiciel gÃ©nÃ¨re en sortie plusieurs dossiers, chacun contenant un ou plusieurs fichiers Excel. Ces fichiers regroupent les indicateurs extraits, ainsi que des mÃ©tadonnÃ©es sur les enregistrements analysÃ©s.
- **Import dans MARS** : les rÃ©sultats gÃ©nÃ©rÃ©s par ABOSA sont sous forme de fichiers Excel. Les indicateurs conservÃ©s sont dans le fichier *ParameterValues*. Ils sont intÃ©grÃ©s dans les tables appropriÃ©es de la base de donnÃ©es MARS, Ã  partir dâ€™une mÃ©thode POST qui envoie ces donnÃ©es Ã  une API sous forme de payloads *json*.

---

# ğŸ”§ Stack technique

- **Langage principal** : Python 3.10+
- **Structure du projet** : Organisation modulaire sous `src/` avec deux packages :
    - `indicator_pipeline` : gestion des connexions, conversions, interactions DB
    - `sleeplab_converter` : conversion des donnÃ©es PSG au format sleeplab
- **Orchestration du pipeline** : `Snakemake` (dÃ©fini dans le `Snakefile`)
- **Environnement reproductible** via `Docker` (dÃ©fini dans le `Dockerfile`) pour garantir la reproductibilitÃ© de lâ€™environnement dâ€™exÃ©cution
- **Gestion de projet & dÃ©pendances** : `pyproject.toml`
- **Logs** : Configuration personnalisÃ©e avec `logging_config.py`
- **Connexion SFTP** : Utilisation dâ€™un client SFTP maison (`sftp_client.py`)
- **Base de donnÃ©es** : IntÃ©gration dans la base MARS (MySQL)
- **Formats manipulÃ©s** :
    - Fichiers **EDF** (biosignaux)
    - Fichiers dâ€™**annotations** (*.csv*, *.txt*, *.rtf*)
    - Fichiers **Excel**
- **Librairies externes** :
    - Manipulation des fichiers EDF : `pyedflib`, `mne`
    - Traitement des donnÃ©es : `pandas`, `numpy`, `tqdm`, `openpyxl`
    - Connexions & systÃ¨me : `paramiko`, `python-dotenv`
    - Fichiers spÃ©cifiques : `striprtf`, `sleeplab-format`
- **Environnement cible** : Machine dÃ©diÃ©e ou VM sous Windows (le systÃ¨me est requis pour exÃ©cuter ABOSA, incompatible avec Linux ou macOS)

---

# ğŸ—‚ï¸ Structure du projet

```markdown
indicator-pipeline/
â”œâ”€â”€ logs/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ indicator_pipeline/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ excel_to_json.py
â”‚   â”‚   â”œâ”€â”€ logging_config.py
â”‚   â”‚   â”œâ”€â”€ run_pipeline.py
â”‚   â”‚   â”œâ”€â”€ sftp_client.py
â”‚   â”‚   â”œâ”€â”€ slf_conversion.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â””â”€â”€ sleeplab_converter/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ edf.py
â”‚       â”œâ”€â”€ events_mapping.py
â”‚       â””â”€â”€ mars_database/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ annotation.py
â”‚           â”œâ”€â”€ convert.py
â”‚           â”œâ”€â”€ LICENSE.txt
â”‚           â””â”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Snakefile
â””â”€â”€ README.md
```

- `logs/` â€“ Emplacement des fichiers de logs gÃ©nÃ©rÃ©s.
- `src/`
    - `indicator_pipeline/`
        - Contient les scripts principaux du pipeline : module principal `run_pipeline`, connexion au serveur sftp `sftp_client`, conversion des psg en .slf `slf_conversion`, dump des donnÃ©es ABOSA en excel dans un payload json `excel_to_json`, la configuration du logger `logging_config`, et fonctions `utils`.
    - `sleeplab_converter/`
        - Convertisseur des fichiers de polysomnographie au format sleeplab, code provenant du [repo git](https://github.com/HP2-data/sleeplab-converter-mars) `sleeplab-converter-mars`.
        - Sous module `mars_database/` comportant les modules de conversion et de traitement des fichiers dâ€™annotations spÃ©cifiques aux appareils utilisÃ©s au labo du sommeil du CHU Grenoble.

---

# âš™ï¸ Installation et configuration

## ğŸ” Installation en local

- Le projet est versionnÃ© sur Git et doit Ãªtre clonÃ© localement pour Ãªtre utilisÃ© :
    
    ```bash
    git clone <URL_DU_REPO>
    cd indicator-pipeline
    ```
    
- L'installation des dÃ©pendances se fait via le fichier `pyproject.toml`, qui liste tous les modules nÃ©cessaires. Il est recommandÃ© dâ€™utiliser un environnement virtuel (ex : `venv`) :
    
    ```bash
    python -m venv .venv
    source .venv/Scripts/activate
    pip install .
    ```
    
- Le fichier `.gitignore` exclut notamment :
    - les fichiers de logs
    - les fichiers gÃ©nÃ©rÃ©s par `setuptools`,
    - les fichiers temporaires ou gÃ©nÃ©rÃ©s automatiquement
    - les environnements virtuels (`.venv/`, etc.)
    - les fichiers gÃ©nÃ©rÃ©s par Snakemake (dossier `.snakemake/`, fichier _.done_ et _.flag_)

## ğŸ³ Montage de lâ€™image Docker

- Le projet inclut un fichier `Dockerfile` pour permettre une **exÃ©cution isolÃ©e et reproductible** sans configuration locale.
- Construction de lâ€™image Docker :
    
    ```bash
    docker build -t indicator-pipeline .
    ```
    
- **Sur Windows**, assurez-vous que Docker Desktop est configurÃ© pour autoriser lâ€™accÃ¨s au disque utilisÃ© (gÃ©nÃ©ralement `C:`).
- Les chemins dâ€™accÃ¨s, notamment vers les fichiers `.env`, doivent Ãªtre accessibles depuis le conteneur.

## âš™ï¸ Configuration de lâ€™environnement `.env`

- Le pipeline utilise un fichier `.env` pour stocker des **variables dâ€™environnement sensibles ou spÃ©cifiques Ã  lâ€™environnement dâ€™exÃ©cution**, comme les identifiants SFTP ou ou les chemins des dossiers utilisÃ©s.
- Exemple de fichier `.env` :

```bash
SFTP_HOST=mon.serveur.com
SFTP_USER=user
SFTP_KEY_PATH=pathtosshkey
SFTP_PASSWORD=motdepasse
SFTP_PORT=sftpport
ABOSA_OUTPUT_PATH=/abosa-output
LOG_OUTPUT_PATH=/app/logs
```

- Emplacement :
    - Le fichier `.env` doit Ãªtre placÃ© Ã  la **racine du projet** (au mÃªme niveau que `pyproject.toml`).
    - Il est automatiquement chargÃ© grÃ¢ce Ã  la librairie [`python-dotenv`](https://pypi.org/project/python-dotenv/) dans les modules concernÃ©s.
    - âš ï¸ **Ne jamais versionner ce fichier** : il est ignorÃ© par `.gitignore`.

---

# ğŸš€ ExÃ©cution du pipeline

âš ï¸ **Important** : le pipeline s'exÃ©cute en **deux temps**, avec une **Ã©tape manuelle intermÃ©diaire**.

1. **Phase 1 â€“ Automatique**
    
    Conversion des fichiers PSG au format *slf* (via script ou Snakemake)
    
2. **Phase 2 â€“ Manuelle**
    
    Analyse des dossiers *slf* via le logiciel ABOSA (hors pipeline). 
    
3. **Phase 3 â€“ Automatique**
    
    Import des rÃ©sultats gÃ©nÃ©rÃ©s par ABOSA dans la base de donnÃ©es (via script ou Snakemake)
    

Cette sÃ©paration est **gÃ©rÃ©e automatiquement** dans lâ€™exÃ©cution via Snakemake, grÃ¢ce Ã  des **fichiers de synchronisation** (`slf_conversion.done`, `abosa_complete.flag`, etc.).

âš™ï¸ En exÃ©cution manuelle, il est de la responsabilitÃ© de lâ€™utilisateur de **lancer les Ã©tapes une par une** et de sâ€™assurer que lâ€™analyse ABOSA est faite avant de poursuivre.

### ğŸ Option 1 â€“ ExÃ©cution orchestrÃ©e via Snakemake (RecommandÃ©e)

- Le projet inclut un `Snakefile` dÃ©finissant les Ã©tapes du pipeline sous forme de rÃ¨gles Snakemake.
- Les **volumes Docker sont gÃ©nÃ©rÃ©s dynamiquement** dans le `Snakefile`, en fonction de lâ€™environnement local de lâ€™utilisateur. Les chemins suivants sont utilisÃ©s :
    - `~/Desktop/slf-output` â†’ dossier de sortie *slf* local
    - `~/Desktop/indicator-pipeline/logs` â†’ fichiers de logs
    - `~/Desktop/abosa-output` â†’ fichiers gÃ©nÃ©rÃ©s par ABOSA et utilisÃ©s dans la deuxiÃ¨me partie du pipeline
- Lancement :
    
    ```bash
    snakemake --config years="2024 2025" --cores 1
    ```
    
- L'argument `--config years="2024 2025"` permet de spÃ©cifier les annÃ©es Ã  traiter lors de l'exÃ©cution du pipeline. Si aucune annÃ©e n'est prÃ©cisÃ©e, **l'annÃ©e en cours est utilisÃ©e par dÃ©faut**.
- Cette mÃ©thode garantit une **exÃ©cution modulaire, traÃ§able et reproductible** des diffÃ©rentes Ã©tapes.
- Lâ€™exÃ©cution complÃ¨te suit trois rÃ¨gles :
    1. `run_pipeline` : convertit les fichiers PSG au format *slf*
    2. `wait_for_manual_step` : Ã©tape manuelle via ABOSA (*cf. Calcul des indicateurs avec ABOSA*)
    3. `import_to_mars` : envoie les rÃ©sultats dans la base MARS
- **Fichiers de synchronisation** (`.done`, `.flag`)
    - `slf_conversion.done` : marque la fin de lâ€™Ã©tape de conversion (`run_pipeline`)
    - `abosa_complete.flag` : fichier **Ã  crÃ©er manuellement** aprÃ¨s lâ€™analyse ABOSA pour continuer lâ€™exÃ©cution. Un fichier `create_flag.bat` est disponible dans le rÃ©pertoire pour crÃ©er ce fichier.
    - `analysis_complete.done` : marque la fin de lâ€™import dans MARS (`import_to_mars`)
    
    Ces fichiers servent de **marqueurs dâ€™Ã©tape** permettant Ã  Snakemake de suivre lâ€™avancement du pipeline. Ils sont crÃ©Ã©s ou vÃ©rifiÃ©s automatiquement par les rÃ¨gles, et peuvent Ãªtre supprimÃ©s avec la commande lorsque tout le pipeline a Ã©tÃ© exÃ©cutÃ© :
    
    ```bash
    snakemake clean --cores 1
    ```
    

ğŸ“ **Remarque** : les chemins par dÃ©faut du Snakefile pointent vers le **Bureau de lâ€™utilisateur** (`~/Desktop`). Si le projet est exÃ©cutÃ© depuis un autre emplacement, il faudra **adapter les chemins dÃ©finis dans le `Snakefile` (variables `SLF_OUTPUT`, `LOGS_DIR`, etc.)** en consÃ©quence.

### ğŸ§ª Option 2 â€“ ExÃ©cution manuelle (script principal)

- Commande principale pour lancer le pipeline (script principal `run_pipeline.py`)
    
    ```bash
    run-pipeline --step slf_conversion --years 2022 2023
    run-pipeline --step import_to_mars
    ```
    
- **Arguments** :
    - `--step`  : *Obligatoire*. Etape du pipeline Ã  exÃ©cuter. Deux valeurs possibles :
        - `slf_conversion` : conversion des fichiers de polysomnographie au format *slf*.
        - `import_to_mars` : import des donnÃ©es produites par ABOSA dans la base MARS.
    - `--years` : *Obligatoire pour lâ€™Ã©tape `slf_conversion` ; non requis pour `import_to_mars`.* AnnÃ©e(s) Ã  traiter, chaque annÃ©e correspondant Ã  un dossier du mÃªme nom sur le serveur de stockage SFTP. Les annÃ©es Ã  traiter doivent Ãªtre sÃ©parÃ©es par des espaces (ex: `--years 2024 2025`)

---

# ğŸ¦Œ Calcul des indicateurs avec ABOSA

Afin de calculer les indicateurs du signal SpOâ‚‚, il faut utiliser le logiciel ABOSA manuellement. Une fois que la premiÃ¨re Ã©tape du pipeline a Ã©tÃ© rÃ©alisÃ©e, les dossiers convertis en *slf* sont stockÃ©s dans le dossier `slf-output`, contenant un sous-dossier par annÃ©e. 

### ParamÃ¨tres de calcul

Une fois lâ€™interface graphique dâ€™ABOSA ouverte, les paramÃ¨tres suivants sont Ã  rÃ©gler :

- Bouton *Select input folder* (1) â‡’ sÃ©lectionner le dossier correspondant Ã  lâ€™**annÃ©e** Ã  traiter `../slf-output/year`. Ce dossier doit se trouver **au mÃªme niveau que le dÃ©pÃ´t Git** (sur le bureau, par exemple),  et **non pas Ã  lâ€™intÃ©rieur du dÃ©pÃ´t**.
- Bouton *Select output folder* (2) â‡’  sÃ©lectionner le dossier de sortie. Les sorties doivent se faire dans le dossier `../abosa-output/year`.  Lui aussi doit Ãªtre situÃ© **au mÃªme niveau que le dÃ©pÃ´t Git** (sur le bureau, par exemple). Si le dossier relatif Ã  lâ€™annÃ©e nâ€™existe pas encore, il faut le crÃ©er manuellement.
- Option *Input file type* (3) â‡’ cocher â€œ*SLFâ€*
- Option *Artefact removal* (4) â‡’ cocher *â€œYesâ€*

![*Interface graphique du logiciel ABOSA*](ABOSA_interface_(1).png)

*Interface graphique du logiciel ABOSA*

### Signal de saturation

Une fois les paramÃ¨tres remplis, cliquer sur le bouton *â€œRUNâ€* (5). Une fenÃªtre sâ€™ouvre pour choisir sur quel signal se baser pour calculer les indicateurs. SÃ©lectionner celui correspondant Ã  la saturation dans la liste â€œ*primary label*â€ **(6), et rajouter les autres formats possibles dans la partie â€œ*secondary labels*â€ (7) grÃ¢ce au bouton *â€œAddâ€* (8). Les diffÃ©rents formats du signal de saturation sont les suivants :

- SAT
- Sp02
- SpO2
- SaO2 SaO2

Enfin, pour lancer le calcul des indicateurs, appuyer sur le bouton *â€œConfirm selectionâ€* (9).

![*Interface permettant de sÃ©lectionner les labels des signaux de saturation avant de lancer les calculs*](ABOSA_interface_(2).png)

*Interface permettant de sÃ©lectionner les labels des signaux de saturation avant de lancer les calculs*

### ğŸ“ƒ Fichiers de sortie

Une fois les calculs des indicateurs effectuÃ©s, plusieurs fichiers sont Ã©ditÃ©s en sortie. Ils sont rÃ©partis en trois dossiers :

- `EventData_<date_et_heure_du_calcul>`
Regroupe les fichiers Excel contenant les Ã©vÃ©nements individuels de dÃ©saturation et rÃ©cupÃ©ration pour chaque fichier *SLF* traitÃ©.
- `ExtraInfo_<date_et_heure_du_calcul>` 
Regroupe les fichiers texte contenant les mÃ©tadonnÃ©es relatives au calcul pour chaque fichier *SLF* traitÃ©. On y retrouve les paramÃ¨tres de dÃ©tection et de nettoyage, les durÃ©es de sommeil par stade, les infos techniques (Ã©tiquette utilisÃ©e pour le signal SpOâ‚‚ par exemple), la dÃ©tection dâ€™artefacts, ainsi que les causes dâ€™Ã©chec de lâ€™analyse en cas de problÃ¨me.
- `ParametersValues_<date_et_heure_du_calcul>` 
Contient un fichier Excel `ParameterValues` unique qui regroupe l'ensemble des valeurs de paramÃ¨tres calculÃ©es Ã  partir des fichiers *SLF* (une ligne par fichier PAxxxx_Vx). 
Ce dossier contient Ã©galement un fichier texte `FileNotes` regroupant toutes les Ã©tiquettes de signal de saturation en oxygÃ¨ne saisies et le premier fichier depuis lequel l'Ã©tiquette de saturation primaire en oxygÃ¨ne est rÃ©cupÃ©rÃ©e.

**NB** : Les donnÃ©es utilisÃ©es dans la deuxiÃ¨me partie du pipeline et intÃ©grÃ©es dans la base de donnÃ©es MARS sont celles se trouvant dans le fichier `ParameterValues`.

---

# ğŸ Fonctionnement du code du pipeline

## ğŸ”Œ Connexion au serveur SFTP

**`sftp_client.py` - Client SFTP simplifiÃ© basÃ© sur `paramiko`**

Classe utilitaire permettant d'Ã©tablir une connexion SFTP et de transfÃ©rer des fichiers ou dossiers entre un systÃ¨me local et un serveur distant.

- **Constructeur**
    
    `SFTPClient(host: str, user: str = "", key_path: str = "", password: str = "", port: int = 22)`
    
    Initialise un client SFTP avec les informations de connexion nÃ©cessaires (utilisateur, mot de passe ou clÃ© privÃ©e, port). Ces informations sensibles sont stockÃ©es dans un fichier `.env` (cf. *Configuration de lâ€™environnement `.env`* ci-dessus).
    Supporte l'authentification par mot de passe **ou** par clÃ© SSH.
    
- **MÃ©thodes**
    - `connect()`
        
        Ã‰tablit une connexion au serveur SFTP distant Ã  lâ€™aide des identifiants fournis.
        
    - `list_files(path: str = "."): List[str]`
        
        Liste les fichiers et dossiers prÃ©sents dans le rÃ©pertoire `path` du serveur distant. Renvoie la liste des noms de fichiers et/ou dossiers
        
    - `is_dir(path: str): bool`
        
        VÃ©rifie si un chemin distant correspond Ã  un dossier.
        
    - `download_folder_recursive(remote_path: str, local_path: Path)`
        
        TÃ©lÃ©charge rÃ©cursivement tout le contenu dâ€™un dossier distant vers un rÃ©pertoire local.
        
    - `upload_folder_recursive(local_path: Path, remote_path: str)`
        
        TransfÃ¨re rÃ©cursivement un dossier local et tout son contenu vers un dossier distant.
        
    - `close()`
        
        Ferme proprement la connexion SFTP et libÃ¨re les ressources.
        

---

## ğŸ”„ Conversion PSG vers .slf

### Module `slf_conversion.py`

Ce module contient la classe `SLFConversion`, qui centralise la logique de conversion des enregistrements de polysomnographie au format *slf* (via lâ€™outil `sleeplab-converter`) ainsi que leur tÃ©lÃ©versement sur le serveur SFTP distant.

- **Classe `SLFConversion`**
    
    `SLFConversion(local_slf_output: Path, remote_year_dir: PurePosixPath, sftp_client: SFTPClient)`
    Initialise un objet permettant de gÃ©rer le cycle de conversion et de transfert des fichiers *slf* pour une annÃ©e donnÃ©e, en sâ€™appuyant sur un dossier de sortie local et un chemin distant sur le serveur.
    
    **ParamÃ¨tres**
    
    - `local_slf_output (Path)` : Chemin local vers le dossier de sortie *slf*, typiquement `../slf-output`.
    - `year_dir (PurePosixPath)` : Chemin distant vers le dossier d'une annÃ©e spÃ©cifique sur le serveur SFTP (ex. `/.../C1/2025`).
    - `sftp_client (SFTPClient)` : Client SFTP actif permettant l'accÃ¨s aux fichiers distants.
    
    **MÃ©thodes**
    
    - `convert_folder_to_slf(local_slf_output: Path, year_dir: PurePosixPath, sftp_client: SFTPClient)`
        
        TÃ©lÃ©charge tous les dossiers de patients pour une annÃ©e donnÃ©e depuis un serveur SFTP dans un dossier temporaire local, ignorant ceux ayant dÃ©jÃ  une sortie *slf*  existante. Les autres dossiers sont convertis au format *slf*  grÃ¢ce au convertisseur `sleeplab-converter` (via la mÃ©thode `convert_dataset`).
        Les dossiers *slf* gÃ©nÃ©rÃ©s sont ensuite enregistrÃ©s localement dans un dossier `slf-output`, situÃ© Ã  l'extÃ©rieur du dÃ©pÃ´t Git.
        
    - `upload_slf_folders_to_server(local_slf_output: Path, remote_year_dir: PurePosixPath, sftp_client: SFTPClient)`
        
        TÃ©lÃ©verse tous les dossiers *slf* gÃ©nÃ©rÃ©s localement vers le rÃ©pertoire distant correspondant Ã  lâ€™annÃ©e et au numÃ©ro de patient, sur le serveur SFTP. Effectue une vÃ©rification de cohÃ©rence entre les noms de dossiers *slf* et les identifiants prÃ©sents dans les fichiers *.edf* distants pour Ã©viter toute erreur dâ€™association.
        

### Package `sleeplab_converter`

- **Gestion des fichiers EDF** - **`edf.py`**
    
    Ce module fournit des fonctions utilitaires pour lire et extraire efficacement les donnÃ©es Ã  partir des fichiers EDF (European Data Format), qui sont couramment utilisÃ©s pour stocker des enregistrements de polysomnographie.
    
    Il permet deux modes de lecture :
    
    - **Lecture directe via `pyedflib`**, pour accÃ©der finement aux signaux et en-tÃªtes.
    - **Lecture via la bibliothÃ¨que `MNE`**, plus robuste pour certaines annotations, mais potentiellement plus lente.
- **Package `mars-database/`**
    
    Ce package permet de faire le traitement des fichiers de polysomnographie Ã©ditÃ©s par les appareils utilisÃ©s par le laboratoire du sommeil du CHU de Grenoble. 
    
    - **Module de conversion en *slf* - `convert.py`**
    Ce module permet de convertir des enregistrements de polysomnographie au format *slf* (SleepLab Format), en sâ€™appuyant sur `sleeplab_format`. Il sâ€™occupe Ã©galement de parser les fichiers *edf* et leurs annotations associÃ©es.
    - **Traitement des fichiers dâ€™annotation - `annotation.py`**
        
        Ce module lit, harmonise et convertit des **fichiers dâ€™annotations de sommeil** provenant de plusieurs appareils de mesures du sommeil (*Deltamed*, *RemLogic*, *BrainRT*) afin de les rendre compatibles avec le format du convertisseur **Sleeplab**.
        
- **Mapping des Ã©vÃ©nements - `events_mapping.py`**
    
    Ce module centralise les rÃ¨gles de correspondance (mapping) entre les Ã©vÃ©nements et stades de sommeil prÃ©sents dans les fichiers dâ€™annotations issus de diffÃ©rents appareils de polysomnographie, et les objets structurÃ©s de la librairie `sleeplab_format`.
    
    Il permet de convertir des annotations hÃ©tÃ©rogÃ¨nes (formats .csv, .txt, .rtf, etc.) en Ã©vÃ©nements normalisÃ©s et exploitables par le reste du pipeline, en sâ€™adaptant Ã  la nomenclature propre Ã  chaque appareil (*Deltamed*, *BrainRT* et *Remlogic*).
    

---

## ğŸ“¦ Conversion Excel vers JSON

- `excel_to_json.py`
    
    Ce module extrait des donnÃ©es de fichiers Excel gÃ©nÃ©rÃ©s par ABOSA, les stocke dans des payloads au format *json*, pour ensuite les envoyer en mÃ©thode POST Ã  une API les stockant dans la base de donnÃ©es MARS.
    Il maintient Ã©galement un suivi des fichiers dÃ©jÃ  traitÃ©s pour Ã©viter les doublons.
    
    - `load_processed(): Set[str]`
        
        Charge la liste des fichiers dÃ©jÃ  traitÃ©s depuis un fichier `processed.json`. Renvoie un ensemble de chemins relatifs identifiant les dossiers dÃ©jÃ  convertis.
        
    - `save_processed(processed_set): None`
        
        Sauvegarde lâ€™ensemble des fichiers marquÃ©s comme dÃ©jÃ  traitÃ©s dans le fichier `processed.json`.
        
    - `find_parameter_folders(abosa_output_path: Path): List[Path]`
        
        Parcourt le dossier de sortie d'ABOSA pour dÃ©tecter tous les sous-dossiers contenant des donnÃ©es (`ParameterValues_...`). Renvoie la liste des chemins vers ces sous-dossiers.
        
    - `get_excel_from_rel_path(folder_path: Path, rel_path: str): pd.DataFrame`
        
        Charge le fichier Excel contenu dans un dossier donnÃ©. DÃ©clenche une erreur si aucun fichier `.xlsx` n'est trouvÃ©.
        
    - `df_to_json_payloads(df: pd.DataFrame): List[Dict[str, Any]]`
        
        Transforme chaque ligne dâ€™un DataFrame Excel en un dictionnaire Python conforme au schÃ©ma JSON attendu :
        
        - Extraction dâ€™identifiants patients et visites
        - Conversion numÃ©rique en *int* (entier) ou *float* (relatif) grÃ¢ce Ã  la fonction `try_parse_number(value, as_int: bool = False): Optional[Union[int, float]]` permettant dâ€™Ã©viter les erreurs.
        - Structuration des champs par catÃ©gories (`desaturation`, `recovery`, `ratios`, etc.) reprÃ©sentant les tables de MARS dans lesquelles les donnÃ©es seront envoyÃ©es.
        
        Renvoie une liste de dictionnaires, chacun reprÃ©sentant un enregistrement patient.
        
    - `excel_to_json(): None`
        
        Fonction principale du module.
        
        Elle orchestre l'ensemble du processus :
        
        - Recherche les fichiers Ã  traiter
        - Ignore ceux dÃ©jÃ  traitÃ©s
        - Convertit les fichiers Excel en JSON
        - Sauvegarde les fichiers gÃ©nÃ©rÃ©s dans `logs/json_dumps`
        - Met Ã  jour le fichier `processed.json`

---

## ğŸ§° Utilitaires

- `utils.py` â€“ fonctions utilitaires communes utilisÃ©es Ã  travers plusieurs modules
    - `parse_patient_and_visit(filename: str): Tuple[str, str]`
        
        Extrait lâ€™identifiant du patient et le numÃ©ro de visite dâ€™une chaÃ®ne de caractÃ¨re (nom de fichier contenant les patterns *PxxxxVx* ou *Pxxxx_Vx*. 
        Renvoie un tuple contenant lâ€™identifiant du patient et le numÃ©ro de visite sous forme de chaÃ®nes de caractÃ¨re.
        
    - `extract_subject_id_from_filename(edf_file: Path): str`
        
        Extrait lâ€™identifiant patient et le numÃ©ro de visite Ã  partir dâ€™un chemin de fichier edf. Renvoie une chaÃ®ne de caractÃ¨re de la forme â€œPAxxxx_Vxâ€ (ou â€œPAxxxxâ€ si pas de numÃ©ro de visite).
        
    - `try_parse_number(value, as_int: bool = False): Optional[Union[int, float]]`
        
        Convertit une chaÃ®ne de caractÃ¨re en *int* ou *float* et remplace les virgules par des points pour gÃ©rer les formats dÃ©cimaux europÃ©ens. Retourne le nombre ou None si la conversion Ã©choue.
        
    - `get_repo_root(): Path`
        
        Renvoie le chemin racine du dÃ©pÃ´t Git.
        
    - `get_local_slf_output(): Path`
        
        Renvoie le chemin complet du dossier de sortie local utilisÃ© pour stocker les .slf (`slf-output/`).
        
    - `lowercase_extensions(dir_path: Path)`
        
        Convertit toutes les extensions des fichiers dâ€™un dossier donnÃ© en minuscule.
        

---

## ğŸ“ Logging

- `logging_config.py` - Utilitaires de configuration du journal (logging)
    - `setup_logging(years: List[str]): None`
        
        Configure le systÃ¨me de journalisation pour la pipeline en crÃ©ant :
        
        - un fichier de log principal (messages de niveau INFO et plus)
        - un fichier sÃ©parÃ© pour les avertissements et erreurs (niveau WARNING et plus)
        
        Les fichiers de log sont enregistrÃ©s dans le dossier `logs/` et leur nom contient les annÃ©es sÃ©lectionnÃ©es ainsi quâ€™un horodatage pour garantir leur unicitÃ©.
        

---

# ğŸ“„ Ressources et annexes

- `README.md` â€“ rÃ©sumÃ© gÃ©nÃ©ral
- `LICENSE.txt` â€“ licence du convertisseur [**sleeplab-converter-mars**](https://github.com/HP2-data/sleeplab-converter-mars)